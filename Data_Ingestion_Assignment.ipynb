{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb0a4b69",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "We want to investigate different ways of reading in a large CSV file when using Python. The goal is to compare the computational efficiency of different methods. We will use three methods, which are listed below:\n",
    "\n",
    "* Pandas\n",
    "* Dask\n",
    "* Modin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20abadd3",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a80fbc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from dask import dataframe as dask_df\n",
    "import modin.pandas as mpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d033e4",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "The dataset used here is an artificial version of the iris dataset. To artificially increase the size of the file, the original dataset was concatenated with itself for many iterations. Thus, the new CSV file, called \"big_iris\", consists of many copies of the original iris dataset joined together. The size of the resulting CSV file is 2.9 GB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c42dc2",
   "metadata": {},
   "source": [
    "# Comparing the different methods of reading in the CSV file\n",
    "\n",
    "The code cells below read in the data using all 3 methods, and print out the time taken for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a86a6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas:  29.57462501525879 seconds\n"
     ]
    }
   ],
   "source": [
    "# Pandas \n",
    "s_time = time.time()\n",
    "df1 = pd.read_csv(\"big_iris.csv\")\n",
    "e_time = time.time()\n",
    "print(\"Pandas: \", (e_time-s_time), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c7c47ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read with dask:  0.012249231338500977 seconds\n"
     ]
    }
   ],
   "source": [
    "# Dask\n",
    "s_time_dask = time.time()\n",
    "df2 = dask_df.read_csv('big_iris.csv')\n",
    "e_time_dask = time.time()\n",
    "print(\"Read with dask: \", (e_time_dask-s_time_dask), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1fe8212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Dask execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    from distributed import Client\n",
      "\n",
      "    client = Client()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modin:  16.61344289779663 seconds\n"
     ]
    }
   ],
   "source": [
    "# Modin\n",
    "s_time_modin = time.time()\n",
    "df3 = mpd.read_csv(\"big_iris.csv\")\n",
    "e_time_modin = time.time()\n",
    "print(\"Modin: \", (e_time_modin-s_time_modin), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f233c75",
   "metadata": {},
   "source": [
    "Our findings show that Dask is the most computationally efficient in this case, as it takes the least amount of time. Pandas takes the longest time to read in the data, and Modin is in between."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018137b3",
   "metadata": {},
   "source": [
    "# Basic data validation\n",
    "\n",
    "Here, we perform basic data validation on the columns of the data. We remove any special characters and white spaces that might be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a12ce91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm',\n",
       "       'Species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop first column from data \n",
    "df2 = df2.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Get all columns\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ea1789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=45\n",
       "    object\n",
       "       ...\n",
       "     ...  \n",
       "       ...\n",
       "       ...\n",
       "Name: Species, dtype: object\n",
       "Dask Name: str-strip, 1035 tasks"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data type to string\n",
    "df2 = df2.astype(str)\n",
    "\n",
    "# Remove special characters\n",
    "df2['Id'] = df2['Id'].str.replace('\\W', '', regex=True)\n",
    "df2['SepalLengthCm'] = df2['SepalLengthCm'].str.replace('\\W', '', regex=True)\n",
    "df2['SepalWidthCm'] = df2['SepalWidthCm'].str.replace('\\W', '', regex=True)\n",
    "df2['PetalLengthCm'] = df2['PetalLengthCm'].str.replace('\\W', '', regex=True)\n",
    "df2['PetalWidthCm'] = df2['PetalWidthCm'].str.replace('\\W', '', regex=True)\n",
    "df2['Species'] = df2['Species'].str.replace('\\W', '', regex=True)\n",
    "\n",
    "# Remove white spaces\n",
    "df2['Id'].str.strip()\n",
    "df2['SepalLengthCm'].str.strip()\n",
    "df2['SepalWidthCm'].str.strip()\n",
    "df2['PetalLengthCm'].str.strip()\n",
    "df2['PetalWidthCm'].str.strip()\n",
    "df2['Species'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d74af5",
   "metadata": {},
   "source": [
    "# Writing testutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17126a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testutility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testutility.py\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import datetime \n",
    "import gc\n",
    "import re\n",
    "\n",
    "\n",
    "################\n",
    "# File Reading #\n",
    "################\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "\n",
    "def replacer(string, char):\n",
    "    pattern = char + '{2,}'\n",
    "    string = re.sub(pattern, char, string) \n",
    "    return string\n",
    "\n",
    "def col_header_val(df,table_config):\n",
    "    '''\n",
    "    replace whitespaces in the column\n",
    "    and standardized column names\n",
    "    '''\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]','_',regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns = list(map(lambda x: replacer(x,'_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns =list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777415ac",
   "metadata": {},
   "source": [
    "# Write YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c4d3c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting file.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile file.yaml\n",
    "file_type: csv\n",
    "dataset_name: testfile\n",
    "file_name: big_iris\n",
    "table_name: edsurv\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - Id\n",
    "    - SepalLengthCm\n",
    "    - SepalWidthCm\n",
    "    - PetalLengthCm\n",
    "    - PetalWidthCm\n",
    "    - Species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b1398f",
   "metadata": {},
   "source": [
    "# Data Validation with YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd739930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config file\n",
    "import testutility as util\n",
    "config_data = util.read_config_file(\"file.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f291ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'dataset_name': 'testfile',\n",
       " 'file_name': 'big_iris',\n",
       " 'table_name': 'edsurv',\n",
       " 'inbound_delimiter': ',',\n",
       " 'outbound_delimiter': '|',\n",
       " 'skip_leading_rows': 1,\n",
       " 'columns': ['Id',\n",
       "  'SepalLengthCm',\n",
       "  'SepalWidthCm',\n",
       "  'PetalLengthCm',\n",
       "  'PetalWidthCm',\n",
       "  'Species']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting data of config file\n",
    "config_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5789641a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normal reading process of the file\n",
    "df_sample = pd.read_csv(\"big_iris.csv\",delimiter=',')\n",
    "df_sample = df_sample.drop(columns=['Unnamed: 0'])\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e55748a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the file using config file\n",
    "file_type = config_data['file_type']\n",
    "source_file = \"./\" + config_data['file_name'] + f'.{file_type}'\n",
    "df = pd.read_csv(source_file,config_data['inbound_delimiter'])\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2cbd1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation passed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the header of the file\n",
    "util.col_header_val(df,config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccf4ce03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns of files are: Index(['id', 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm',\n",
      "       'species'],\n",
      "      dtype='object')\n",
      "columns of YAML are: ['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']\n"
     ]
    }
   ],
   "source": [
    "print(\"columns of files are:\" ,df.columns)\n",
    "print(\"columns of YAML are:\" ,config_data['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d43ac697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation passed\n",
      "col validation passed\n"
     ]
    }
   ],
   "source": [
    "if util.col_header_val(df,config_data)==0:\n",
    "    print(\"validation failed\")\n",
    "else:\n",
    "    print(\"col validation passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd31c228",
   "metadata": {},
   "source": [
    "# Writing the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2743ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "df.to_csv('my_file.txt', header=True, index=False, sep=config_data['outbound_delimiter'], mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a978434",
   "metadata": {},
   "source": [
    "# Summary of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "902cdd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has 78643200 rows\n",
      "The file has 6 columns\n",
      "The file size is 7.930380483 gigabytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"The file has\", df.shape[0], \"rows\")\n",
    "print(\"The file has\", df.shape[1], \"columns\")\n",
    "file_size = os.path.getsize('my_file.txt')\n",
    "file_size_gb = file_size * 10**-9\n",
    "print(\"The file size is\", file_size_gb, \"gigabytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
